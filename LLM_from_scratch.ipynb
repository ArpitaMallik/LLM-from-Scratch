{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W645fS1DrS55",
        "outputId": "7b39241f-9ff4-48bf-f0ad-416bf3d06c9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of characters:  20479\n",
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
          ]
        }
      ],
      "source": [
        "with open(\"/content/the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "  raw_text = f.read()\n",
        "\n",
        "print(\"Total number of characters: \", len(raw_text))\n",
        "print(raw_text[:99])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "text = \"Hello, world. This, is a test.\"\n",
        "res = re.split(r'(\\s)', text)\n",
        "\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tv3asmHJto5u",
        "outputId": "a06d63e5-22ce-42d2-bdd5-458a1411cb49"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello,', ' ', 'world.', ' ', 'This,', ' ', 'is', ' ', 'a', ' ', 'test.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = re.split(r'([,.] | \\s)', text)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZMJN3WpuRan",
        "outputId": "fb6478cb-1b15-41fa-9efc-67c6782c6bec"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ', ', 'world', '. ', 'This', ', ', 'is a test.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = [item for item in res if item.strip()]\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXqcP4zeuc6i",
        "outputId": "aed9dab1-9e89-4078-912d-537304c25cf3"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ', ', 'world', '. ', 'This', ', ', 'is a test.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hello, world. Is this-- a test?\"\n",
        "res = re.split(r'([,.:;?_!\"()\\'] | -- | \\s)', text)\n",
        "res = [item.strip() for item in res if item.strip()]\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtGnOoN55pG3",
        "outputId": "f8dc8b75-765b-476e-976c-f5a826b3e4fa"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'world', '.', 'Is this-- a test?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
        "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
        "print(preprocessed[:30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8PP9lCG7H1c",
        "outputId": "2e5477a0-0c9c-4265-d06f-909a97b10263"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(preprocessed))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAnhrV-6-VLX",
        "outputId": "2c2944a7-75d4-4557-b4e8-7b43af9241a5"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Assigning token IDs"
      ],
      "metadata": {
        "id": "8eE6nHHY7QVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_words = sorted(set(preprocessed))\n",
        "vocab_size = len(all_words)\n",
        "print(vocab_size)\n",
        "print(all_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ro_nEYTX-baf",
        "outputId": "29b7d0bb-9112-41d2-b82c-816d3797e4af"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1130\n",
            "['!', '\"', \"'\", '(', ')', ',', '--', '.', ':', ';', '?', 'A', 'Ah', 'Among', 'And', 'Are', 'Arrt', 'As', 'At', 'Be', 'Begin', 'Burlington', 'But', 'By', 'Carlo', 'Chicago', 'Claude', 'Come', 'Croft', 'Destroyed', 'Devonshire', 'Don', 'Dubarry', 'Emperors', 'Florence', 'For', 'Gallery', 'Gideon', 'Gisburn', 'Gisburns', 'Grafton', 'Greek', 'Grindle', 'Grindles', 'HAD', 'Had', 'Hang', 'Has', 'He', 'Her', 'Hermia', 'His', 'How', 'I', 'If', 'In', 'It', 'Jack', 'Jove', 'Just', 'Lord', 'Made', 'Miss', 'Money', 'Monte', 'Moon-dancers', 'Mr', 'Mrs', 'My', 'Never', 'No', 'Now', 'Nutley', 'Of', 'Oh', 'On', 'Once', 'Only', 'Or', 'Perhaps', 'Poor', 'Professional', 'Renaissance', 'Rickham', 'Riviera', 'Rome', 'Russian', 'Sevres', 'She', 'Stroud', 'Strouds', 'Suddenly', 'That', 'The', 'Then', 'There', 'They', 'This', 'Those', 'Though', 'Thwing', 'Thwings', 'To', 'Usually', 'Venetian', 'Victor', 'Was', 'We', 'Well', 'What', 'When', 'Why', 'Yes', 'You', '_', 'a', 'abdication', 'able', 'about', 'above', 'abruptly', 'absolute', 'absorbed', 'absurdity', 'academic', 'accuse', 'accustomed', 'across', 'activity', 'add', 'added', 'admirers', 'adopted', 'adulation', 'advance', 'aesthetic', 'affect', 'afraid', 'after', 'afterward', 'again', 'ago', 'ah', 'air', 'alive', 'all', 'almost', 'alone', 'along', 'always', 'am', 'amazement', 'amid', 'among', 'amplest', 'amusing', 'an', 'and', 'another', 'answer', 'answered', 'any', 'anything', 'anywhere', 'apparent', 'apparently', 'appearance', 'appeared', 'appointed', 'are', 'arm', 'arm-chair', 'arm-chairs', 'arms', 'art', 'articles', 'artist', 'as', 'aside', 'asked', 'at', 'atmosphere', 'atom', 'attack', 'attention', 'attitude', 'audacities', 'away', 'awful', 'axioms', 'azaleas', 'back', 'background', 'balance', 'balancing', 'balustraded', 'basking', 'bath-rooms', 'be', 'beaming', 'bean-stalk', 'bear', 'beard', 'beauty', 'became', 'because', 'becoming', 'bed', 'been', 'before', 'began', 'begun', 'behind', 'being', 'believed', 'beneath', 'bespoke', 'better', 'between', 'big', 'bits', 'bitterness', 'blocked', 'born', 'borne', 'boudoir', 'bravura', 'break', 'breaking', 'breathing', 'bric-a-brac', 'briefly', 'brings', 'bronzes', 'brought', 'brown', 'brush', 'bull', 'business', 'but', 'buying', 'by', 'called', 'came', 'can', 'canvas', 'canvases', 'cards', 'care', 'career', 'caught', 'central', 'chair', 'chap', 'characteristic', 'charming', 'cheap', 'check', 'cheeks', 'chest', 'chimney-piece', 'chucked', 'cigar', 'cigarette', 'cigars', 'circulation', 'circumstance', 'circus-clown', 'claimed', 'clasping', 'clear', 'cleverer', 'close', 'clue', 'coat', 'collapsed', 'colour', 'come', 'comfortable', 'coming', 'companion', 'compared', 'complex', 'confident', 'congesting', 'conjugal', 'constraint', 'consummate', 'contended', 'continued', 'corner', 'corrected', 'could', 'couldn', 'count', 'countenance', 'couple', 'course', 'covered', 'craft', 'cried', 'crossed', 'crowned', 'crumbled', 'cry', 'cured', 'curiosity', 'curious', 'current', 'curtains', 'd', 'dabble', 'damask', 'dark', 'dashed', 'day', 'days', 'dead', 'deadening', 'dear', 'deep', 'deerhound', 'degree', 'delicate', 'demand', 'denied', 'deploring', 'deprecating', 'deprecatingly', 'desire', 'destroyed', 'destruction', 'desultory', 'detail', 'diagnosis', 'did', 'didn', 'died', 'dim', 'dimmest', 'dingy', 'dining-room', 'disarming', 'discovery', 'discrimination', 'discussion', 'disdain', 'disdained', 'disease', 'disguised', 'display', 'dissatisfied', 'distinguished', 'distract', 'divert', 'do', 'doesn', 'doing', 'domestic', 'don', 'done', 'donkey', 'down', 'dozen', 'dragged', 'drawing-room', 'drawing-rooms', 'drawn', 'dress-closets', 'drew', 'dropped', 'each', 'earth', 'ease', 'easel', 'easy', 'echoed', 'economy', 'effect', 'effects', 'efforts', 'egregious', 'eighteenth-century', 'elbow', 'elegant', 'else', 'embarrassed', 'enabled', 'end', 'endless', 'enjoy', 'enlightenment', 'enough', 'ensuing', 'equally', 'equanimity', 'escape', 'established', 'etching', 'even', 'event', 'ever', 'everlasting', 'every', 'exasperated', 'except', 'excuse', 'excusing', 'existed', 'expected', 'exquisite', 'exquisitely', 'extenuation', 'exterminating', 'extracting', 'eye', 'eyebrows', 'eyes', 'face', 'faces', 'fact', 'faded', 'failed', 'failure', 'fair', 'faith', 'false', 'familiar', 'famille-verte', 'fancy', 'fashionable', 'fate', 'feather', 'feet', 'fell', 'fellow', 'felt', 'few', 'fewer', 'finality', 'find', 'fingers', 'first', 'fit', 'fitting', 'five', 'flash', 'flashed', 'florid', 'flowers', 'fluently', 'flung', 'follow', 'followed', 'fond', 'footstep', 'for', 'forced', 'forcing', 'forehead', 'foreign', 'foreseen', 'forgive', 'forgotten', 'form', 'formed', 'forming', 'forward', 'fostered', 'found', 'foundations', 'fragment', 'fragments', 'frame', 'frames', 'frequently', 'friend', 'from', 'full', 'fullest', 'furiously', 'furrowed', 'garlanded', 'garlands', 'gave', 'genial', 'genius', 'gesture', 'get', 'getting', 'give', 'given', 'glad', 'glanced', 'glimpse', 'gloried', 'glory', 'go', 'going', 'gone', 'good', 'good-breeding', 'good-humoured', 'got', 'grace', 'gradually', 'gray', 'grayish', 'great', 'greatest', 'greatness', 'grew', 'groping', 'growing', 'had', 'hadn', 'hair', 'half', 'half-light', 'half-mechanically', 'hall', 'hand', 'hands', 'handsome', 'hanging', 'happen', 'happened', 'hard', 'hardly', 'has', 'have', 'haven', 'having', 'he', 'head', 'hear', 'heard', 'heart', 'height', 'her', 'here', 'hermit', 'herself', 'hesitations', 'hide', 'high', 'him', 'himself', 'hint', 'his', 'history', 'holding', 'home', 'honour', 'hooded', 'hostess', 'hot-house', 'hour', 'hours', 'house', 'how', 'hung', 'husband', 'idea', 'idle', 'idling', 'if', 'immediately', 'in', 'incense', 'indifferent', 'inevitable', 'inevitably', 'inflexible', 'insensible', 'insignificant', 'instinctively', 'instructive', 'interesting', 'into', 'ironic', 'irony', 'irrelevance', 'irrevocable', 'is', 'it', 'its', 'itself', 'jardiniere', 'jealousy', 'just', 'keep', 'kept', 'kind', 'knees', 'knew', 'know', 'known', 'laid', 'lair', 'landing', 'language', 'last', 'late', 'later', 'latter', 'laugh', 'laughed', 'lay', 'leading', 'lean', 'learned', 'least', 'leathery', 'leave', 'led', 'left', 'leisure', 'lends', 'lent', 'let', 'lies', 'life', 'life-likeness', 'lift', 'lifted', 'light', 'lightly', 'like', 'liked', 'line', 'lines', 'lingered', 'lips', 'lit', 'little', 'live', 'll', 'loathing', 'long', 'longed', 'longer', 'look', 'looked', 'looking', 'lose', 'loss', 'lounging', 'lovely', 'lucky', 'lump', 'luncheon-table', 'luxury', 'lying', 'made', 'make', 'man', 'manage', 'managed', 'mantel-piece', 'marble', 'married', 'may', 'me', 'meant', 'mediocrity', 'medium', 'mentioned', 'mere', 'merely', 'met', 'might', 'mighty', 'millionaire', 'mine', 'minute', 'minutes', 'mirrors', 'modest', 'modesty', 'moment', 'money', 'monumental', 'mood', 'morbidly', 'more', 'most', 'mourn', 'mourned', 'moustache', 'moved', 'much', 'muddling', 'multiplied', 'murmur', 'muscles', 'must', 'my', 'myself', 'mysterious', 'naive', 'near', 'nearly', 'negatived', 'nervous', 'nervousness', 'neutral', 'never', 'next', 'no', 'none', 'not', 'note', 'nothing', 'now', 'nymphs', 'oak', 'obituary', 'object', 'objects', 'occurred', 'oddly', 'of', 'off', 'often', 'oh', 'old', 'on', 'once', 'one', 'ones', 'only', 'onto', 'open', 'or', 'other', 'our', 'ourselves', 'out', 'outline', 'oval', 'over', 'own', 'packed', 'paid', 'paint', 'painted', 'painter', 'painting', 'pale', 'paled', 'palm-trees', 'panel', 'panelling', 'pardonable', 'pardoned', 'part', 'passages', 'passing', 'past', 'pastels', 'pathos', 'patient', 'people', 'perceptible', 'perfect', 'persistence', 'persuasively', 'phrase', 'picture', 'pictures', 'pines', 'pink', 'place', 'placed', 'plain', 'platitudes', 'pleased', 'pockets', 'point', 'poised', 'poor', 'portrait', 'posing', 'possessed', 'poverty', 'predicted', 'preliminary', 'presenting', 'prestidigitation', 'pretty', 'previous', 'price', 'pride', 'princely', 'prism', 'problem', 'proclaiming', 'prodigious', 'profusion', 'protest', 'prove', 'public', 'purblind', 'purely', 'pushed', 'put', 'qualities', 'quality', 'queerly', 'question', 'quickly', 'quietly', 'quite', 'quote', 'rain', 'raised', 'random', 'rather', 're', 'real', 'really', 'reared', 'reason', 'reassurance', 'recovering', 'recreated', 'reflected', 'reflection', 'regrets', 'relatively', 'remained', 'remember', 'reminded', 'repeating', 'represented', 'reproduction', 'resented', 'resolve', 'resources', 'rest', 'rich', 'ridiculous', 'robbed', 'romantic', 'room', 'rose', 'rs', 'rule', 'run', 's', 'said', 'same', 'satisfaction', 'savour', 'saw', 'say', 'saying', 'says', 'scorn', 'scornful', 'secret', 'see', 'seemed', 'seen', 'self-confident', 'send', 'sensation', 'sensitive', 'sent', 'serious', 'set', 'sex', 'shade', 'shaking', 'shall', 'she', 'shirked', 'short', 'should', 'shoulder', 'shoulders', 'show', 'showed', 'showy', 'shrug', 'shrugged', 'sight', 'sign', 'silent', 'silver', 'similar', 'simpleton', 'simplifications', 'simply', 'since', 'single', 'sitter', 'sitters', 'sketch', 'skill', 'slight', 'slightly', 'slowly', 'small', 'smile', 'smiling', 'sneer', 'so', 'solace', 'some', 'somebody', 'something', 'spacious', 'spaniel', 'speaking-tubes', 'speculations', 'spite', 'splash', 'square', 'stairs', 'stammer', 'stand', 'standing', 'started', 'stay', 'still', 'stocked', 'stood', 'stopped', 'stopping', 'straddling', 'straight', 'strain', 'straining', 'strange', 'straw', 'stream', 'stroke', 'strokes', 'strolled', 'strongest', 'strongly', 'struck', 'studio', 'stuff', 'subject', 'substantial', 'suburban', 'such', 'suddenly', 'suffered', 'sugar', 'suggested', 'sunburn', 'sunburnt', 'sunlit', 'superb', 'sure', 'surest', 'surface', 'surprise', 'surprised', 'surrounded', 'suspected', 'sweetly', 'sweetness', 'swelling', 'swept', 'swum', 't', 'table', 'take', 'taken', 'talking', 'tea', 'tears', 'technicalities', 'technique', 'tell', 'tells', 'tempting', 'terra-cotta', 'terrace', 'terraces', 'terribly', 'than', 'that', 'the', 'their', 'them', 'then', 'there', 'therefore', 'they', 'thin', 'thing', 'things', 'think', 'this', 'thither', 'those', 'though', 'thought', 'three', 'threshold', 'threw', 'through', 'throwing', 'tie', 'till', 'time', 'timorously', 'tinge', 'tips', 'tired', 'to', 'told', 'tone', 'tones', 'too', 'took', 'tottering', 'touched', 'toward', 'trace', 'trade', 'transmute', 'traps', 'travelled', 'tribute', 'tributes', 'tricks', 'tried', 'trouser-presses', 'true', 'truth', 'turned', 'twenty', 'twenty-four', 'twice', 'twirling', 'unaccountable', 'uncertain', 'under', 'underlay', 'underneath', 'understand', 'unexpected', 'untouched', 'unusual', 'up', 'up-stream', 'upon', 'upset', 'upstairs', 'us', 'used', 'usual', 'value', 'varnishing', 'vases', 've', 'veins', 'velveteen', 'very', 'villa', 'vindicated', 'virtuosity', 'vista', 'vocation', 'voice', 'wall', 'wander', 'want', 'wanted', 'wants', 'was', 'wasn', 'watched', 'watching', 'water-colour', 'waves', 'way', 'weekly', 'weeks', 'welcome', 'went', 'were', 'what', 'when', 'whenever', 'where', 'which', 'while', 'white', 'white-panelled', 'who', 'whole', 'whom', 'why', 'wide', 'widow', 'wife', 'wild', 'wincing', 'window-curtains', 'wish', 'with', 'without', 'wits', 'woman', 'women', 'won', 'wonder', 'wondered', 'word', 'work', 'working', 'worth', 'would', 'wouldn', 'year', 'years', 'yellow', 'yet', 'you', 'younger', 'your', 'yourself']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {token:integer for integer, token in enumerate(all_words)}\n",
        "for i, item in enumerate(vocab.items()):\n",
        "  print(item)\n",
        "  if i >= 50:\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uqKUgsc_nlG",
        "outputId": "afba1413-d803-4fe5-f30f-35c3435f257c"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('!', 0)\n",
            "('\"', 1)\n",
            "(\"'\", 2)\n",
            "('(', 3)\n",
            "(')', 4)\n",
            "(',', 5)\n",
            "('--', 6)\n",
            "('.', 7)\n",
            "(':', 8)\n",
            "(';', 9)\n",
            "('?', 10)\n",
            "('A', 11)\n",
            "('Ah', 12)\n",
            "('Among', 13)\n",
            "('And', 14)\n",
            "('Are', 15)\n",
            "('Arrt', 16)\n",
            "('As', 17)\n",
            "('At', 18)\n",
            "('Be', 19)\n",
            "('Begin', 20)\n",
            "('Burlington', 21)\n",
            "('But', 22)\n",
            "('By', 23)\n",
            "('Carlo', 24)\n",
            "('Chicago', 25)\n",
            "('Claude', 26)\n",
            "('Come', 27)\n",
            "('Croft', 28)\n",
            "('Destroyed', 29)\n",
            "('Devonshire', 30)\n",
            "('Don', 31)\n",
            "('Dubarry', 32)\n",
            "('Emperors', 33)\n",
            "('Florence', 34)\n",
            "('For', 35)\n",
            "('Gallery', 36)\n",
            "('Gideon', 37)\n",
            "('Gisburn', 38)\n",
            "('Gisburns', 39)\n",
            "('Grafton', 40)\n",
            "('Greek', 41)\n",
            "('Grindle', 42)\n",
            "('Grindles', 43)\n",
            "('HAD', 44)\n",
            "('Had', 45)\n",
            "('Hang', 46)\n",
            "('Has', 47)\n",
            "('He', 48)\n",
            "('Her', 49)\n",
            "('Hermia', 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encode and Decode function"
      ],
      "metadata": {
        "id": "dJNJb7BaXdrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTokenizerV1:\n",
        "  def __init__(self, vocab):\n",
        "    self.str_to_int = vocab\n",
        "    self.int_to_str = {i:s for s,i in vocab.items()}\n",
        "\n",
        "  def encode(self,text):\n",
        "    preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
        "    preprocessed = [\n",
        "        item.strip() for item in preprocessed if item.strip()\n",
        "    ]\n",
        "    ids = [self.str_to_int[s] for s in preprocessed]\n",
        "    return ids\n",
        "\n",
        "  def decode(self,ids):\n",
        "    text = \" \".join([self.int_to_str[i] for i in ids])\n",
        "    text = re.sub(r'\\s+([,.:;?_!\"()\\'])', r'\\1', text)\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "tsuk1bws7VLK"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = SimpleTokenizerV1(vocab)\n",
        "\n",
        "text = \"\"\"\"It's the last he painted, you know,\"\n",
        "          Mrs. Gisburn said with pardonable pride.\"\"\"\n",
        "\n",
        "ids = tokenizer.encode(text)\n",
        "print(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJnLvrORq1rO",
        "outputId": "8d09ab76-fb38-4316-db4f-f630d25d9842"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "BGNya7jJsR_E",
        "outputId": "60232774-100f-4f23-94ac-bcacccce69cd"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\" It\\' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding special context tokens (unk and endoftoken)"
      ],
      "metadata": {
        "id": "qHDjQAyItAya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_tokens = sorted(list(set(preprocessed)))\n",
        "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
        "\n",
        "vocab = {token:integer for integer, token in enumerate(all_tokens)}\n",
        "print(len(vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8VCSbmmtETl",
        "outputId": "bced62d4-681e-41dc-c19b-d65f3883a65a"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, item in enumerate(list(vocab.items())[-5:]):\n",
        "  print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fBHyQWI_F-z",
        "outputId": "26d6cf1a-75aa-41ac-93a3-c8627ffe0537"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('younger', 1127)\n",
            "('your', 1128)\n",
            "('yourself', 1129)\n",
            "('<|endoftext|>', 1130)\n",
            "('<|unk|>', 1131)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTokenizerV2:\n",
        "  def __init__(self, vocab):\n",
        "    self.str_to_int = vocab\n",
        "    self.int_to_str = {i:s for s,i in vocab.items()}\n",
        "\n",
        "  def encode(self,text):\n",
        "    preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
        "    preprocessed = [\n",
        "        item.strip() for item in preprocessed if item.strip()\n",
        "    ]\n",
        "    preprocessed = [\n",
        "        item if item in self.str_to_int\n",
        "        else \"<|unk|>\" for item in preprocessed\n",
        "    ]\n",
        "    ids = [self.str_to_int[s] for s in preprocessed]\n",
        "    return ids\n",
        "\n",
        "  def decode(self,ids):\n",
        "    text = \" \".join([self.int_to_str[i] for i in ids])\n",
        "    text = re.sub(r'\\s+([,.:;?_!\"()\\'])', r'\\1', text)\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "UwLs_HRA_-29"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = SimpleTokenizerV2(vocab)\n",
        "\n",
        "text1 = \"Hello, do you like tea?\"\n",
        "text2 = \"In the sunlit terraces of the palace.\"\n",
        "\n",
        "text = \"<|endoftext|>\".join((text1,text2))\n",
        "\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvSlYMHEF3wW",
        "outputId": "473dc3f7-faa8-4857-95ec-11542312e93d"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, do you like tea?<|endoftext|>In the sunlit terraces of the palace.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(text)"
      ],
      "metadata": {
        "id": "ggzef6phGOj5",
        "outputId": "b90e66b5-e01c-4bea-b3b8-70b3651c9a66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1131, 5, 355, 1126, 628, 975, 10, 1131, 988, 956, 984, 722, 988, 1131, 7]"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(tokenizer.encode(text))"
      ],
      "metadata": {
        "id": "O0QKR8_pGSC4",
        "outputId": "f6b69355-3340-4cbf-98e5-b08c7a378e87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|unk|>, do you like tea? <|unk|> the sunlit terraces of the <|unk|>.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Byte Pair Encoding"
      ],
      "metadata": {
        "id": "YxrSHlRe-hWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "8QwBH7A50-FS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4e4ea90-bb81-403b-ae00-4e61289ac81e"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.12.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2025.11.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "PMwJZatp-uph"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = (\n",
        "    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces of someunknownPlace.\"\n",
        ")\n",
        "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "print(integers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSJuEnbi_ZXY",
        "outputId": "d2cc4a8d-6cfa-4aab-c113-91ef163fe38e"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 286, 617, 34680, 27271, 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strings = tokenizer.decode_batch([integers])\n",
        "print(strings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgNffeR8AtOk",
        "outputId": "b8ee81a4-abcf-458d-9962-ccb1c6972099"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello, do you like tea? <|endoftext|> In the sunlit terraces of someunknownPlace.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The <endoftext> token is assigned a relatively large token ID, namely, 50256. <br>\n",
        "#### In fact, the BPE tokenizer, which was used to train models such as GPT-2 and 3, and the original GPT model used in ChatGPT, has a total vocabulary size of 50,257, with <endoftext> being assigned the larget token ID. <br>\n",
        "#### The BPE tokenizer above encodes and decoeds unknown words, such as \"someunknownPlace\" correctly. The BPE tokenizer can handle any unkown word. How does it achieve this without using <|unk|> tokens? <br>\n",
        "#### The algoritm underlying BPE breaks down words that aren't in its predefined vocabulary into smaller sub word units or even individual characters. This enables it to handle out of vocabulary words. <br>\n"
      ],
      "metadata": {
        "id": "o7qWhh_zA7rD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "integers = tokenizer.encode(\"Akwirw ier\")\n",
        "print(integers)\n",
        "\n",
        "strings = tokenizer.decode(integers)\n",
        "print(strings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKaquNfECrnx",
        "outputId": "cea49def-771b-4c68-fb39-34b479826e33"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[33901, 86, 343, 86, 220, 959]\n",
            "Akwirw ier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lecture 9: Creating Input-Target data pairs using Python Dataloader**"
      ],
      "metadata": {
        "id": "ZRYZAKjUEYgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "  raw_text = f.read()\n",
        "\n",
        "enc_text = tokenizer.encode(raw_text)\n",
        "print(len(enc_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2j7rABhDpV7",
        "outputId": "f00af663-7ae1-4db7-f884-4bf38b64b0c5"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_sample = enc_text[50:]"
      ],
      "metadata": {
        "id": "pJfbN4OiF2DU"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The context size determines how many tokens are included in the input."
      ],
      "metadata": {
        "id": "M4lAilU0Cagw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context_size = 10\n",
        "#The context_size = 4 means that the model is trianed to look at a sequence of 4 words\n",
        "#to predict the next word in the sequence.\n",
        "\n",
        "x = enc_sample[:context_size]\n",
        "y = enc_sample[1:context_size+1]\n",
        "\n",
        "print(f\"x = {x}\")\n",
        "print(f\"y = {y}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-lWD8uZCevq",
        "outputId": "4ad5a45c-7a71-4c7d-8fe1-e517630963aa"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = [290, 4920, 2241, 287, 257, 4489, 64, 319, 262, 34686]\n",
            "y = [4920, 2241, 287, 257, 4489, 64, 319, 262, 34686, 41976]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, context_size+1):\n",
        "  context = enc_sample[:i]\n",
        "  desired = enc_sample[i]\n",
        "\n",
        "  print(context, \"--->\", desired)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hl6YP5n3Dr_w",
        "outputId": "2a8df9e8-000c-42e2-f7e5-af1aeaea80f2"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[290] ---> 4920\n",
            "[290, 4920] ---> 2241\n",
            "[290, 4920, 2241] ---> 287\n",
            "[290, 4920, 2241, 287] ---> 257\n",
            "[290, 4920, 2241, 287, 257] ---> 4489\n",
            "[290, 4920, 2241, 287, 257, 4489] ---> 64\n",
            "[290, 4920, 2241, 287, 257, 4489, 64] ---> 319\n",
            "[290, 4920, 2241, 287, 257, 4489, 64, 319] ---> 262\n",
            "[290, 4920, 2241, 287, 257, 4489, 64, 319, 262] ---> 34686\n",
            "[290, 4920, 2241, 287, 257, 4489, 64, 319, 262, 34686] ---> 41976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Everything that's left of the arrow referes to the input an LLM would receive, and the token ID on the right side of the arrow represents the target token id which the LLM is supposed to predict."
      ],
      "metadata": {
        "id": "N3Ku1lNhE85m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, context_size+1):\n",
        "  context = enc_sample[:i]\n",
        "  desired = enc_sample[i]\n",
        "\n",
        "  print(tokenizer.decode(context), \"--->\", tokenizer.decode([desired]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEMsVEPeFbkp",
        "outputId": "07cceb75-2fcc-4466-d781-e1d94d00d994"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " and --->  established\n",
            " and established --->  himself\n",
            " and established himself --->  in\n",
            " and established himself in --->  a\n",
            " and established himself in a --->  vill\n",
            " and established himself in a vill ---> a\n",
            " and established himself in a villa --->  on\n",
            " and established himself in a villa on --->  the\n",
            " and established himself in a villa on the --->  Riv\n",
            " and established himself in a villa on the Riv ---> iera\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We will implement a data loader that fetches input-output target pairs using a **sliding window** approach."
      ],
      "metadata": {
        "id": "44sxosAFJZc0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Tokenize the entire text <br>\n",
        "Step 2: Use a sliding window to chunk the book into overlappibg sequences of max_length <br>\n",
        "Step 3: Return the total number of rows in the dataset\n",
        "<br>\n",
        "Step 4: Return a single row from the dataset"
      ],
      "metadata": {
        "id": "mZGRzGQCOfkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "  def __init__(self, txt, tokenizer, max_length, stride):\n",
        "    self.input_ids = []\n",
        "    self.target_ids = []\n",
        "\n",
        "    #tokenize the entire text\n",
        "    token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "    #use a sliding window to chunk the book into overlapping sequences of max_length\n",
        "    for i in range(0, len(token_ids) - max_length, stride):\n",
        "      input_chunk = token_ids[i:i+max_length]\n",
        "      target_chunk = token_ids[i+1:i+max_length+1]\n",
        "\n",
        "      self.input_ids.append(torch.tensor(input_chunk))\n",
        "      self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      return self.input_ids[idx], self.target_ids[idx]"
      ],
      "metadata": {
        "id": "J0SXs2RfJgvI"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code will use the GPTDatasetV1 to load the inputs in batches via a Pytorch DataLoader.\n",
        "<br>\n",
        "<br>\n",
        "Step 1: Initialize the tokenizer. <br>\n",
        "Step 2: Create dataset <br>\n",
        "Step 3: drop_last = True drops the last batch if it is shorter than the specified batch_size to prevent loss spikes durinng training <br>\n",
        "Step 4: The number of CPU processes to use for the preprocessing"
      ],
      "metadata": {
        "id": "gHG1qXQ-D_08"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are using the dataloader because it can do parallel processing and it can handle mulitple batches at once."
      ],
      "metadata": {
        "id": "xo2xA38sH_5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
        "                         stride=128, shuffle=True, drop_last=True,\n",
        "                         num_workers=0):\n",
        "\n",
        "  #initialize the tokenizer\n",
        "  tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "  #create dataset\n",
        "  dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "\n",
        "  #create dataloader\n",
        "  dataloader = DataLoader(dataset,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=shuffle,\n",
        "                          drop_last=drop_last,\n",
        "                          num_workers=num_workers)\n",
        "\n",
        "  return dataloader"
      ],
      "metadata": {
        "id": "FQHW-NbUEgKz"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = create_dataloader_v1(\n",
        "    raw_text, batch_size=1, max_length=4, stride=1, shuffle=False\n",
        ")\n",
        "\n",
        "data_iter = iter(dataloader)\n",
        "first_batch = next(data_iter)\n",
        "print(first_batch)"
      ],
      "metadata": {
        "id": "cO1Jp522IcaR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "459d07b0-69c1-47c3-f2ac-923e8cf826f6"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "second_batch = next(data_iter)\n",
        "print(second_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2VaKQpRL6OU",
        "outputId": "d3e221a0-cc3f-4607-a036-4fc1b09fc6d5"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[ 367, 2885, 1464, 1807]]), tensor([[2885, 1464, 1807, 3619]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In deep learning, small batch sizer require less memory during training but lead to more noisy model updates. <br>\n",
        "Just like in regular deep learning, the batch size is a trade-off and hyperparameter to experiment with when training LLMs."
      ],
      "metadata": {
        "id": "gaJ2OfTAMGL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = create_dataloader_v1(\n",
        "    raw_text, batch_size=8, max_length=4, stride=4, shuffle=False\n",
        ")\n",
        "\n",
        "data_iter = iter(dataloader)\n",
        "first_batch = next(data_iter)\n",
        "print(first_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0tPp6KUMlqo",
        "outputId": "fffefee6-6caa-474d-a8ba-ba7dd20e90fa"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[   40,   367,  2885,  1464],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [10899,  2138,   257,  7026],\n",
            "        [15632,   438,  2016,   257],\n",
            "        [  922,  5891,  1576,   438],\n",
            "        [  568,   340,   373,   645],\n",
            "        [ 1049,  5975,   284,   502],\n",
            "        [  284,  3285,   326,    11]]), tensor([[  367,  2885,  1464,  1807],\n",
            "        [ 3619,   402,   271, 10899],\n",
            "        [ 2138,   257,  7026, 15632],\n",
            "        [  438,  2016,   257,   922],\n",
            "        [ 5891,  1576,   438,   568],\n",
            "        [  340,   373,   645,  1049],\n",
            "        [ 5975,   284,   502,   284],\n",
            "        [ 3285,   326,    11,   287]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "More overlap could lead to more overfitting. So it is an advantage of using larger stride."
      ],
      "metadata": {
        "id": "GANYx7YHNMhj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lecture 10**"
      ],
      "metadata": {
        "id": "eFPfZk-p59E_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Token Embeddings"
      ],
      "metadata": {
        "id": "4bn_6rYgv-TL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the sake of simplicity, we select a small vocabulary of only 6 words instead of 50,257 words in the BPE tokenizer vocabulary, and we want to create embeddings of size 3 (in GPT-3, the embedding size is 12,286 dimensions)"
      ],
      "metadata": {
        "id": "xFcPB-BmwKwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = torch.tensor([2,3,5,1])"
      ],
      "metadata": {
        "id": "5WPvJlL7NF5U"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the vocab_size and output_dim, we can instantiate an embedding layer in Pytorch, setting the random seed to 123 for reproducibility purposes."
      ],
      "metadata": {
        "id": "vfYvWzZIxsxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 6\n",
        "output_dim = 3\n",
        "\n",
        "torch.manual_seed(123)\n",
        "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
      ],
      "metadata": {
        "id": "hyo5MWzzwJWs"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The print statement in the code prints the embedding layer's underlying weight matrix"
      ],
      "metadata": {
        "id": "A7OwAukx0Z_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_layer.weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOgCkfqYyTEM",
        "outputId": "e485b9d6-b2c0-4e87-b867-6b9de9af72a0"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.3374, -0.1778, -0.1690],\n",
            "        [ 0.9178,  1.5810,  1.3010],\n",
            "        [ 1.2753, -0.2010, -0.1606],\n",
            "        [-0.4015,  0.9666, -1.1481],\n",
            "        [-1.1589,  0.3255, -0.6315],\n",
            "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_layer(torch.tensor([3])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qY-kad5a0jnE",
        "outputId": "f3581d8a-49a2-4bee-c99c-1d0bd06c93a2"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is why embedding vector is also called a **lookup table** that stores embeddings of a fixed dictionary and size."
      ],
      "metadata": {
        "id": "MRWM4eDh2keW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The embedding layer is a lookup operation that retrieves rows from the embedding layer weight matrix using a token ID."
      ],
      "metadata": {
        "id": "8Sn7LdcB3rCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_layer(input_ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UpUMN9x2SpV",
        "outputId": "64085441-8ce4-4758-8301-dd95a2702a0d"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.2753, -0.2010, -0.1606],\n",
            "        [-0.4015,  0.9666, -1.1481],\n",
            "        [-2.8400, -0.7849, -1.4096],\n",
            "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lecture 11**"
      ],
      "metadata": {
        "id": "3BCuHLbST0R0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Positional Embeddings (Encoding word positions)"
      ],
      "metadata": {
        "id": "avxbbcEXUEOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 50257\n",
        "output_dim = 256\n",
        "\n",
        "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
      ],
      "metadata": {
        "id": "7JDrLluFT2dV"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 4\n",
        "dataloader = create_dataloader_v1(\n",
        "    raw_text, batch_size=8, max_length=max_length, stride=max_length, shuffle=False\n",
        ")\n",
        "data_iter = iter(dataloader)\n",
        "inputs, target = next(data_iter)"
      ],
      "metadata": {
        "id": "-YFNejv-Yq_s"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Token IDs:\\n \", inputs)\n",
        "print(\"Inputs shape: \", inputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhlhNyDfiAx1",
        "outputId": "89384ca0-2216-42ac-8d68-d9794f8646ff"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs:\n",
            "  tensor([[   40,   367,  2885,  1464],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [10899,  2138,   257,  7026],\n",
            "        [15632,   438,  2016,   257],\n",
            "        [  922,  5891,  1576,   438],\n",
            "        [  568,   340,   373,   645],\n",
            "        [ 1049,  5975,   284,   502],\n",
            "        [  284,  3285,   326,    11]])\n",
            "Inputs shape:  torch.Size([8, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_embeddings = token_embedding_layer(inputs)\n",
        "print(token_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaEDHle-tXev",
        "outputId": "2e0d0683-3f6c-455f-dac0-784835652176"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_id = torch.tensor(40, dtype=torch.long)\n",
        "vector = token_embedding_layer(token_id)\n",
        "print(vector.shape)\n",
        "print(vector)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3XH_85vthfv",
        "outputId": "dfd0d5a7-85ae-445a-d2f7-69d97b6c7020"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256])\n",
            "tensor([ 4.9130e-01,  1.1239e+00,  1.4588e+00, -3.6530e-01, -4.0372e-02,\n",
            "         1.9042e-01,  6.8024e-01, -8.6577e-01,  2.7644e-01,  6.3706e-01,\n",
            "        -1.5947e+00, -2.6210e-02, -1.4804e+00, -1.0301e+00, -1.2018e+00,\n",
            "         1.2016e+00,  1.8119e+00,  1.9705e+00,  1.6373e-01, -5.1866e-01,\n",
            "         5.2069e-01, -1.0986e+00,  4.8871e-01,  4.3105e-01,  1.2858e+00,\n",
            "        -1.9670e+00,  9.2041e-02,  4.5699e-01, -1.4753e+00, -4.4934e-01,\n",
            "        -8.3517e-01, -1.1789e+00, -6.0601e-01, -5.3533e-01, -2.9543e-01,\n",
            "         5.1638e-01,  4.2293e-01,  2.7947e-01, -2.4484e+00,  3.0050e-01,\n",
            "         3.5847e-01,  7.4261e-01,  2.1654e-01, -9.2025e-01,  2.2604e-01,\n",
            "        -8.0408e-01,  6.7722e-01,  8.9504e-01, -1.3292e+00, -1.6186e+00,\n",
            "        -1.6062e+00, -8.2329e-01,  1.1738e-01, -7.6778e-01,  9.9370e-01,\n",
            "         5.0167e-02,  7.0607e-02, -7.8336e-01,  4.4577e-01, -3.5213e-01,\n",
            "         7.3934e-01,  3.3461e-01, -5.5481e-01, -3.8830e-01,  9.9484e-01,\n",
            "         5.0054e-02, -1.5199e+00,  2.6316e-01, -1.6431e-01, -1.8176e-01,\n",
            "        -1.2671e+00, -3.9901e-01,  1.1806e+00, -1.2890e+00,  2.6386e-01,\n",
            "         5.0294e-01, -1.9135e-02, -8.5628e-01,  3.2852e+00,  4.7334e-01,\n",
            "         3.5021e-01,  1.5031e+00,  6.1182e-03,  1.0935e+00,  5.9817e-01,\n",
            "        -2.4226e-01,  4.3834e-01,  2.8703e-01, -6.3067e-02,  1.5893e+00,\n",
            "         9.4539e-01,  2.4572e+00, -1.8282e+00, -9.1278e-01,  4.2322e-01,\n",
            "         3.8999e-01,  2.8728e+00,  9.2387e-01, -1.0545e+00, -1.6685e-01,\n",
            "         4.9418e-02, -5.7389e-01,  2.1188e-01, -1.4189e-01,  2.5842e-01,\n",
            "        -1.1669e+00,  3.2978e-01,  2.0646e+00, -2.8099e-03,  1.1904e+00,\n",
            "        -9.8472e-01,  2.8700e+00,  2.8058e-01, -9.5489e-01,  2.0992e-02,\n",
            "         4.6095e-02,  5.6878e-01, -1.0328e+00, -1.5094e+00, -1.0096e+00,\n",
            "         3.9668e-01,  3.9019e-01,  3.0298e-01, -1.7095e-01,  6.5605e-01,\n",
            "         4.6227e-01,  1.3236e+00, -9.9633e-02, -7.5895e-01,  4.5632e-01,\n",
            "         1.1187e+00,  1.3849e+00, -7.4361e-01,  1.9304e+00,  5.3987e-01,\n",
            "        -3.5931e-01, -5.0138e-01,  2.0892e+00, -2.6761e-01,  2.3729e+00,\n",
            "        -3.5865e-01,  1.4453e-01, -1.5189e+00, -1.1551e+00, -3.2523e-01,\n",
            "         1.0416e+00,  5.7471e-02,  3.1885e-01, -6.3204e-01,  4.3194e-01,\n",
            "        -1.1108e+00,  8.8609e-01, -1.7648e+00,  9.9688e-02,  1.5095e+00,\n",
            "        -2.4513e-03,  6.1941e-02, -1.5005e+00, -1.6771e+00,  1.8315e+00,\n",
            "        -4.4011e-01,  5.5835e-01,  5.9907e-02,  9.9766e-01,  1.1716e+00,\n",
            "         5.5063e-02, -1.6676e-03, -1.5624e+00, -1.7296e+00,  5.7165e-01,\n",
            "         1.4861e+00, -9.5123e-01,  9.3879e-01,  2.1141e-01, -4.3493e-01,\n",
            "        -1.1834e-01, -1.3070e+00,  6.6544e-01,  9.6096e-01, -1.0029e+00,\n",
            "        -2.5464e-02, -8.2375e-01,  1.1840e+00, -1.4371e-02,  1.0247e-01,\n",
            "        -9.6544e-01,  2.5993e-01, -8.1029e-02, -1.0579e+00,  1.6819e-01,\n",
            "        -5.2815e-01,  4.5458e-01,  1.5662e-01, -6.7174e-01,  1.1728e-01,\n",
            "         2.6288e-01,  1.2155e+00,  2.2697e-01, -6.9495e-01, -1.1921e+00,\n",
            "        -2.2795e+00, -6.8390e-01, -8.1515e-01, -4.5456e-01,  1.5426e-01,\n",
            "        -5.1363e-01, -7.9109e-02,  4.7301e-01, -5.1337e-01, -2.9405e-01,\n",
            "        -3.2225e-01, -5.1180e-01, -1.8316e+00, -1.7413e-01, -2.5953e-01,\n",
            "        -1.2352e+00, -2.0569e+00, -1.3432e+00, -5.1492e-01,  5.3491e-01,\n",
            "        -8.0244e-01, -2.3238e+00,  7.7816e-02,  6.6902e-01, -6.2408e-01,\n",
            "        -7.9696e-02, -1.2051e+00, -1.0474e+00,  1.2773e+00,  5.2871e-02,\n",
            "         3.0100e-01,  5.9734e-02, -1.3454e-01,  3.7136e-01, -3.1442e-01,\n",
            "         6.0228e-01,  1.5533e+00,  6.7704e-01, -1.1035e+00, -5.6747e-01,\n",
            "         7.5113e-01,  5.1021e-01, -3.2169e-01, -2.0201e+00, -3.6327e-02,\n",
            "        -6.9542e-01, -3.4297e-01, -4.8025e-01,  3.7921e-01,  1.1108e+00,\n",
            "         1.8160e+00, -5.9255e-02, -1.1052e+00, -3.9954e-01, -1.8735e+00,\n",
            "        -1.4455e-01], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_length = max_length\n",
        "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)"
      ],
      "metadata": {
        "id": "xUdGtDpg0lWK"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_embeddings = pos_embedding_layer(torch.arange(max_length))\n",
        "print(pos_embeddings)\n",
        "print(pos_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eq_dKIZC16o-",
        "outputId": "fb3c8e9b-37fb-40f7-922f-a02f2e4f1b45"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.7375, -0.5620, -0.6303,  ..., -0.2277,  1.5748,  1.0345],\n",
            "        [ 1.6423, -0.7201,  0.2062,  ...,  0.4118,  0.1498, -0.4628],\n",
            "        [-0.4651, -0.7757,  0.5806,  ...,  1.4335, -0.4963,  0.8579],\n",
            "        [-0.6754, -0.4628,  1.4323,  ...,  0.8139, -0.7088,  0.4827]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "torch.Size([4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Token embeddings have shape\n",
        "[batch_size, seq_length, embedding_dim] <br>\n",
        "= [8, 4, 256] <br><br> Positional embeddings have shape\n",
        "[seq_length, embedding_dim] <br>\n",
        "= [4, 256]\n",
        "<br> <br>\n",
        "The magic trick: **Broadcasting**\n",
        "\n",
        "PyTorch sees:\n",
        "\n",
        "Token embeddings: [8, 4, 256] <br>\n",
        "Pos embeddings:   [   4, 256]\n",
        "<br>\n",
        "PyTorch expands the smaller tensor by pretending it has a batch dimension of size 1:\n",
        "<br>\n",
        "Pos embeddings becomes: [1, 4, 256] <br>\n",
        "Then it repeats that row for each of the 8 sequences: <br>\n",
        "[1, 4, 256]  [8, 4, 256]   (virtually, without copying) <br>\n",
        "So, final addition: <br>\n",
        "[8, 4, 256]  +  [8, 4, 256]    [8, 4, 256]"
      ],
      "metadata": {
        "id": "SHmp35sbIw03"
      }
    }
  ]
}